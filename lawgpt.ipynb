{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3330371-4d48-4c69-9430-cda63dd5df8a",
   "metadata": {},
   "source": [
    "# Import necessary modules and classes\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM \n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a0385-e533-4f90-9940-7e52da8df964",
   "metadata": {},
   "source": [
    "# Initialize a directory loader to load PDF documents from a directory\n",
    "loader = DirectoryLoader(\"ipc-data\", glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "# Initialize a text splitter to split documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "\n",
    "# Split the loaded documents into chunks\n",
    "texts = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b47230-092f-4d38-82bc-69ec579e7620",
   "metadata": {},
   "source": [
    "# Creating a Vector DB using Chroma DB and SentenceTransformerEmbeddings\n",
    "# Initialize SentenceTransformerEmbeddings with a pre-trained model\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "# Create a Chroma vector database from the text chunks\n",
    "db = Chroma.from_documents(texts, embeddings, persist_directory=persist_directory)\n",
    "\n",
    "# To save and load the saved vector db (if needed in the future)\n",
    "# Persist the database to disk\n",
    "# db.persist()\n",
    "# db = Chroma(persist_directory=\"db\", embedding_function=embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969562c-5874-417c-b5af-72963e0058e7",
   "metadata": {},
   "source": [
    "# Specify the checkpoint for the language model\n",
    "checkpoint = \"MBZUAI/LaMini-Flan-T5-783M\"\n",
    "\n",
    "# Initialize the tokenizer and base model for text generation\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654ebe8-ccb4-4db5-a583-c87f8b3f971f",
   "metadata": {},
   "source": [
    "# Create a text generation pipeline\n",
    "pipe = pipeline(\n",
    "    'text2text-generation',\n",
    "    model = base_model,\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = 512,\n",
    "    do_sample = True,\n",
    "    temperature = 0.3,\n",
    "    top_p= 0.95\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d712178-9479-40e6-bdcd-21d2b56cdbf5",
   "metadata": {},
   "source": [
    "# Initialize a local language model pipeline\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "# Create a RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=local_llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8fd75-ad34-41ff-aa19-51e7c48baa9b",
   "metadata": {},
   "source": [
    "# Prompt the user for a query\n",
    "input_query = str(input(\"Enter your query:\"))\n",
    "\n",
    "# Execute the query using the QA chain\n",
    "llm_response = qa_chain({\"query\": input_query})\n",
    "\n",
    "# Print the response\n",
    "print(llm_response['result'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
